"""
FastAPI-—Å–µ—Ä–≤–∏—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∏—Å–∫–∞ —Å–µ—Ä–¥–µ—á–Ω–æ–≥–æ –ø—Ä–∏—Å—Ç—É–ø–∞
"""

import json
import io
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import numpy as np

import pandas as pd
from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.responses import FileResponse, StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from catboost import CatBoostClassifier

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BASE_DIR = Path(__file__).parent
MODEL_DIR = BASE_DIR / "models"
STATIC_DIR = BASE_DIR / "static"

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
STATIC_DIR.mkdir(exist_ok=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
try:
    FEATURES = json.loads((MODEL_DIR / "model_features.json").read_text(encoding="utf-8"))
    THRESHOLD_DATA = json.loads((MODEL_DIR / "optimal_threshold.json").read_text(encoding="utf-8"))
    THRESHOLD = float(THRESHOLD_DATA["threshold"])  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã {len(FEATURES)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ—Ä–æ–≥: {THRESHOLD}")
except FileNotFoundError as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    FEATURES = []
    THRESHOLD = 0.5
    logger.warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
try:
    from src.preprocessing.data_preprocessor import DataPreprocessor
    preprocessor = DataPreprocessor(
        drop_leaky_features=True,
        add_missing_anamnesis_flag=True
    )
    logger.info("–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞: {e}")
    preprocessor = None

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
try:
    model_path = MODEL_DIR / "heart_risk_model.cbm"
    if model_path.exists():
        model = CatBoostClassifier().load_model(str(model_path))
        logger.info(f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
    else:
        logger.warning("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞")
        model = None
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="CardioRisk API",
    description="–°–µ—Ä–≤–∏—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∏—Å–∫–∞ —Å–µ—Ä–¥–µ—á–Ω–æ–≥–æ –ø—Ä–∏—Å—Ç—É–ø–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤",
    version="1.0.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# –†–∞–∑–¥–∞—á–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

def numpy_to_python(obj):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy —Ç–∏–ø—ã –≤ Python —Ç–∏–ø—ã"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: numpy_to_python(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [numpy_to_python(item) for item in obj]
    else:
        return obj

def _get_risk_level(probability: float, threshold: float = THRESHOLD) -> Dict[str, str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    
    Args:
        probability: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞ (0.0‚Äì1.0)
        threshold: –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ 'level' –∏ 'label'
    """
    if probability >= 0.7:
        return {"level": "high", "label": "–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫"}
    elif probability >= (threshold - 0.15):
        return {"level": "medium", "label": "–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π —Ä–∏—Å–∫"}
    else:
        return {"level": "low", "label": "–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫"}

def _get_recommendations(risk_level: str, probability: float) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
    
    Args:
        risk_level: –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ (high/medium/low)
        probability: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
        
    Returns:
        –¢–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    """
    if risk_level == "high":
        return "–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å—Ä–æ—á–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –∫–∞—Ä–¥–∏–æ–ª–æ–≥–∞, –≠–ö–ì, –≠—Ö–æ–ö–ì, –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ç—Ä–æ–ø–æ–Ω–∏–Ω."
    elif risk_level == "medium":
        return "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Ç–µ—Ä–∞–ø–µ–≤—Ç–∞, –∫–æ–Ω—Ç—Ä–æ–ª—å –∞—Ä—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è, –≠–ö–ì."
    else:
        return "–ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ—Å–º–æ—Ç—Ä —á–µ—Ä–µ–∑ 6-12 –º–µ—Å—è—Ü–µ–≤, –∑–¥–æ—Ä–æ–≤—ã–π –æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏."

@app.get("/")
async def get_homepage():
    """
    –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    –ü—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π index.html
    """
    return FileResponse(STATIC_DIR / "index.html")

@app.post("/predict")
async def predict_json(
    file: UploadFile = File(..., description="CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤")
) -> Dict[str, Any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç {file.filename}")
    
    return await _process_file(file, output_format="json")

@app.post("/predict/csv")
async def predict_csv(
    file: UploadFile = File(..., description="CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤")
) -> StreamingResponse:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV
    """
    logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ CSV –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç {file.filename}")
    
    return await _process_file(file, output_format="csv")

@app.get("/api/health")
async def health_check() -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞
    """
    return numpy_to_python({
        "status": "healthy" if model else "no_model",
        "timestamp": datetime.now().isoformat(),
        "model_loaded": model is not None,
        "features_count": len(FEATURES),
        "threshold": THRESHOLD,
        "version": "2.0.0"
    })

async def _process_file(
    file: UploadFile, 
    output_format: str = "json"
) -> Dict[str, Any] | StreamingResponse:
    """
    –û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏
    if model is None or preprocessor is None:
        raise HTTPException(
            status_code=503,
            detail="–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞."
        )
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
    if not file.filename.endswith('.csv'):
        raise HTTPException(
            status_code=400, 
            detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ CSV-—Ñ–∞–π–ª—ã"
        )
    
    try:
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        contents = await file.read()
        df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–∫–∏ id
        if 'id' not in df.columns:
            raise HTTPException(
                status_code=400,
                detail="–í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'id'"
            )
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df_processed = preprocessor.transform(df)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        missing_features = set(FEATURES) - set(df_processed.columns)
        if missing_features:
            raise HTTPException(
                status_code=400,
                detail=f"–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {sorted(missing_features)}"
            )
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        proba = model.predict_proba(df_processed[FEATURES])[:, 1]
        pred = (proba >= THRESHOLD).astype(int)
        
        if output_format == "csv":
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ CSV –æ—Ç–≤–µ—Ç–∞
            result_df = pd.DataFrame({
                "id": df["id"],
                "prediction": pred
            })
            
            stream = io.StringIO()
            result_df.to_csv(stream, index=False)
            stream.seek(0)
            
            return StreamingResponse(
                iter([stream.getvalue()]),
                media_type="text/csv",
                headers={
                    "Content-Disposition": "attachment; filename=submission.csv"
                }
            )
        
        else:  # JSON —Ñ–æ—Ä–º–∞—Ç
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            results = []
            for i in range(len(df)):
                risk_info = _get_risk_level(proba[i])
                results.append({
                    "id": int(df.iloc[i]["id"]),
                    "prediction": int(pred[i]),
                    "probability_high_risk": float(proba[i]),
                    "risk_level": risk_info["level"],
                    "risk_level_label": risk_info["label"],
                    "recommendations": _get_recommendations(risk_info["level"], proba[i])
                })
            
            response_data = {
                "predictions": results,
                "metadata": {
                    "total_patients": len(results),
                    "high_risk_count": int(sum(pred)),
                    "low_risk_count": int(len(pred) - sum(pred)),
                    "threshold": float(THRESHOLD)
                }
            }
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ numpy —Ç–∏–ø—ã
            return numpy_to_python(response_data)
    
    except pd.errors.EmptyDataError:
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –ø—É—Å—Ç–æ–π")
    
    except UnicodeDecodeError:
        raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ (–æ–∂–∏–¥–∞–µ—Ç—Å—è UTF-8)")
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = datetime.now()
    
    response = await call_next(request)
    
    process_time = (datetime.now() - start_time).total_seconds()
    logger.info(
        f"{request.method} {request.url.path} "
        f"Status: {response.status_code} "
        f"Time: {process_time:.3f}s"
    )
    
    return response

if __name__ == "__main__":
    import uvicorn
    
    print("‚îÅ" * 75)
    print("üöÄ CardioRisk Prediction System")
    print("‚îÅ" * 75)
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ : {len(FEATURES)}")
    print(f"‚öñÔ∏è –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ : {THRESHOLD}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞    : {'–î–∞' if model else '–ù–µ—Ç'}")
    print(f"üîÑ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä        : {'–î–∞' if preprocessor else '–ù–µ—Ç'}")
    print("‚îÅ" * 75)
    print("üåê –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å       : http://localhost:8000")
    print("üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API    : http://localhost:8000/api/docs")
    print("üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è  : http://localhost:8000/api/health")
    print("‚îÅ" * 75)
    
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=8000,
        log_level="info"
    )